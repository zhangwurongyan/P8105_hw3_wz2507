---
title: "hw3"
author: "Wurongyan Zhang"
date: "10/7/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,message=FALSE}
library(tidyverse)
library(ggridges)
library(gridExtra)
library(data.table)
library(p8105.datasets)
data("instacart")
```

## problem 1

Comment: The data instacart contains `r ncol(instacart)` variables and `r nrow(instacart)` rows which means there are 1,384,617 observations of 131,209 unique users with each row showing the product from one order. The key variables are:

order_dow: the day of the week on which the order was placed

order_hour_of_day: the hour of the day on which the order was placed

product_name: name of the product

aisle: the name of the aisle

department: the name of the department

For example, for the first row, the customer purchased on thursday 10:00. The product name is "Bulgarian Yogurt" and purchased from aisle "yogurt" and department "dairy eggs".

There are 135 aisles in total and the most items are ordered from aisle "fresh vegetables" which has aisle id of 83. 
```{r}
insta = instacart %>% 
  group_by(aisle) %>% 
  count() %>% 
  arrange(n)
insta[which.max(pull(insta,n)),1]
```
```{r}
more = insta %>% 
  filter(n>10000) 

ggplot(more,aes(x=aisle, y=n, fill=6))+
  geom_bar(stat = "identity")+
  theme(axis.text.x = element_text(angle = 90, hjust = 0.9))+
  labs(title = "number of items ordered in each aisle", x="aisle name", y="number of items")

```
Comment: We can see from the plot that in the aisles "fresh vegetables", "fresh fruits" and "packaged vegetable fruits" are three aisles sold the most items.

```{r}
bake = instacart %>% 
  filter(aisle=="baking ingredients") %>% 
  group_by(product_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  head(3)

dog = instacart %>% 
  filter(aisle=="dog food care") %>% 
  group_by(product_name) %>% 
  count() %>% 
  arrange(desc(n))%>% 
  head(3)

pak = instacart %>% 
  filter(aisle=="packaged vegetables fruits") %>% 
  group_by(product_name) %>% 
  count() %>% 
  arrange(desc(n))%>% 
  head(3)

all1= full_join(pak, dog)
all = full_join(all1,bake) 

aisle=c("packaged vegetables fruits","packaged vegetables fruits","packaged vegetables fruits","dog food care","dog food care","dog food care","baking ingredients","baking ingredients","baking ingredients")
bind =
  as.data.frame(aisle)
all3=as.data.frame(c(all, bind)) %>% 
  select(aisle,everything())
all3
```
Comment: for the aisle "baking ingredients", the three most popular items are "Light Brown Sugar",	"Pure Baking Soda", and "Cane Sugar".
For the aisle "dog food care", the three most popular items are "Snack Sticks Chicken & Rice Recipe Dog Treats",	"Organix Chicken & Brown Rice Recipe",	 "Small Dog Biscuits". This aisle has the least total items sold compared to the other two.
For the aisle "packaged vegetables fruits", the three most popular items are "Organic Baby Spinach",	 "Organic Raspberries","Organic Blueberries". This aisle has the most total items sold compared to the other two.



```{r}
pink = instacart %>% 
  filter(product_name %like% "Pink Lady Apples") %>% 
  group_by(order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day) ) %>% 
  mutate(name = "Pink Lady Apples")
pink
```

```{r}
coffee = instacart %>% 
  filter(product_name %like% "Coffee Ice Cream") %>% 
  group_by(order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day) )%>% 
  mutate(name = "Coffee Ice Cream")
com = rbind(pink,coffee)
pivot_wider(com,id_cols = name, names_from = order_dow, values_from = mean_hour)
```
Comment: For pink lady apples, customers ordered mainly from 11:00 to 14:00. For coffee ice cream, customers ordered mainly from 12:00 to 15:00. We can see that those times of the day have overlaps.

# problem 2

```{r}
data("brfss_smart2010")
```

```{r}
overall= brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic=="Overall Health")  %>% 
  mutate(response= factor(response,order=TRUE, levels = c("Excellent","Very good","Good","Fair","Poor"))) %>% 
  arrange(desc(response))
  
 
```

```{r}
loc= overall %>% 
  filter(year=="2002") %>% 
  group_by(locationabbr) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  mutate(n=n/5) %>% 
  #since for each location it measured for 5 times, so I used total n to divide 5
  filter(n>=7)
  
loc
```
 

```{r}
loc10= overall %>% 
  filter(year=="2010") %>% 
  group_by(locationabbr) %>% 
  count() %>% 
  arrange(desc(n)) %>%
  mutate(n=n/5) %>% 
  filter(n>=7)
loc10
```
Comment: There are total 6 states were observed at 7 or more locations in 2002. Also, there are total 14 states were observed at 7 or more locations in 2010.

```{r}
excellent = overall %>% 
  filter(response=="Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarise(mean(data_value)) %>% 
  `colnames<-`(c("year","state","mean_data_value"))  
  
excellent
```

```{r}
ggplot(excellent,
       aes(x=year, y=mean_data_value, color=state))+
  geom_line()+
  labs(title=" average value over time within a state")
```
Comment: We can see that the average value over time within a state mainly range from 15 to 30 and it does not fluctuate a lot within a state but there are some difference between different states. For WV in 2005, the average was extremely low compared to others.




```{r}
data06=overall %>% 
  filter(locationabbr=="NY") %>% 
  group_by(year,locationabbr,data_value,locationdesc,response) %>% 
  filter(year=="2006")

data10=overall %>% 
  filter(locationabbr=="NY") %>% 
  group_by(year,data_value,locationdesc,response) %>% 
  filter(year=="2010")

yr6 = ggplot(data06,aes(x=factor(response, levels = c("Excellent","Very good","Good","Fair","Poor")), y=data_value, color=locationdesc, group=locationdesc))+
  geom_line()+
  geom_point()+
  labs(x="response", title = "Year 2006")


yr10=ggplot(data10,aes(x=factor(response, levels = c("Excellent","Very good","Good","Fair","Poor")), y=data_value, color=locationdesc, group=locationdesc))+
  geom_line()+
  geom_point()+
  labs(x="response", title = "Year 2010")

grid.arrange(yr6, yr10, nrow = 2)


```

Comment: We can see that in year 2010 there are more locations evaluated in the state NY. In both years, "poor" has the lowest data value and "very good" has the highest in 2010 and "good" has the highest in 2006. This means the most of the responses are better than "good" in both years.

```{r,include=FALSE}
data_year=overall %>% 
  filter(locationabbr=="NY") %>%
  filter(year==c("2010","2006"))

plot_year=ggplot(data_year,aes(x=factor(response, levels = c("Excellent","Very good","Good","Fair","Poor")), y=data_value, color=locationdesc, group=locationdesc))+
  geom_line()+
  geom_point()+
  labs(x="response", title = "Distribution of data_value")+
  facet_grid(~year)
plot_year
```

## problem 3
```{r,message=FALSE}
chf = read_csv("./data/accel_data.csv")
```

```{r}
chf = 
  chf %>% 
  janitor::clean_names() %>% 
  mutate(days= ifelse(day =="Saturday"|day=="Sunday", "Weekend", "Weekdays")) %>% 
  pivot_longer(
    starts_with("activity_"),
    names_to = "activity_minutes",
    names_prefix = "activity_",
    values_to = "activity_counts"
  ) %>% 
  mutate(activity_minutes = factor(activity_minutes, levels = c(1:1440)))
```

The variables contain `r head(chf)` and there are total `r ncol(chf)` observations. The "day" variable indicates the day of the week and the "days" variable indicates if it is weekdays or weekends.
```{r}
chf %>% 
  select(day_id, activity_counts,day) %>% 
  group_by(day_id) %>% 
  summarise(total_activity=sum(activity_counts)) 

```

```{r}
test= chf %>% 
  select(day_id, activity_counts,day) %>% 
  group_by(day_id) %>% 
  mutate(total_activity=sum(activity_counts)) %>% 
  ggplot(aes(x=as.factor(day_id), y=total_activity))+
  geom_point()
test
```
From the plot we can see that there are few days(day 2, day 24 and day 31) has low total activity and most days the total activity times range from 
$$2\times10^5\ to\ 6\times10^5$$. There is no particular trend from my perspective.



```{r}
chf %>% 
  select(activity_minutes,day_id,day,activity_counts) %>% 
  ggplot(aes(x=activity_minutes, y=activity_counts, color=day))+
  scale_x_discrete(breaks=seq(60,1440,60), labels=as.character(c(1:24)))+
  geom_point()+
  labs(x="activity hours", y="activity counts", title="24 hour activity time courses for each day")
```

From the plot we can see that on the time between 8:00 to 12:00, the activity counts are high, espectially on Sunday. On Saturday 16:00 to 17:00, the activities are high. This maybe due to people have more time during weekends. On Thursday 7:00, the activity is high, which means there might be some specific events happening on that day. Furthermore, between 20:00 to 22:00, the activity counts are the highest especially for Wednesday. However, most of the activity counts are between 0 to 2500 for each day.






















